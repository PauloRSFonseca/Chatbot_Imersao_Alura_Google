{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNo8x48Z7XguOGUx5WuCcF/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PauloRSFonseca/Chatbot_Imersao_Alura_Google/blob/main/Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalando o SDK do Google"
      ],
      "metadata": {
        "id": "GDhV6ZshZevU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "Ljq50tC9ZPvm"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai # usado para instalar a biblioteca google-generativeai no Python\n",
        "# ! indica ao sistema que o comando subsequente deve ser executado no shell, usado para instalar e gerenciar bibliotecas\n",
        "# install indica que o comando deseja instalar uma biblioteca\n",
        "# pip é o gerenciador de pacotes padrão do Python\n",
        "# -q é usado para ter um resultado silencioso, suprimindo a exibição de mensagens de progesso durante a instalação (quiet)\n",
        "# -U é usada para fazer update do google generativeai, instalando a versão mais recente (Update)\n",
        "# google-generativeai é a biblioteca que será instalada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "HTiaTu6O1LRC"
      },
      "outputs": [],
      "source": [
        "# configura seu ambiente para usar a biblioteca google-generativeai para geração de texto\n",
        "import google.generativeai as julIA # importa a biblioteca e da um apelido a ela julIA\n",
        "# importa a função userdata do Colab, usada para gerenciar dados na sua unidade do Google Drive montada no Colab\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('SECRET_KEY')\n",
        "julIA.configure(api_key=api_key) #configura a biblioteca usando a chave de API definida, permite que use os modelos de geração de texto do Google"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Listar os modelos disponíveis"
      ],
      "metadata": {
        "id": "sYThy2wFaIju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lista os modelos disponíveis na biblioteca google-generativeai e imprime os nome dos modelos que suportam o método de geração de conteúdo\n",
        "for m in julIA.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "cgmg2qqhaXRu",
        "outputId": "05e2cae7-f852-4b7b-c386-7de200904482"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define um dicionário que contém configurações para a geração de texto\n",
        "generation_config = {\n",
        "    'candidate_count': 1, # especifica o número de candidatos de texto a serem gerados\n",
        "    'temperature': 0.5, # controla a criatividade e a aleatoriedade da geração de texto\n",
        "}"
      ],
      "metadata": {
        "id": "eHXkeMK9eyn1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configurando os Padrões de Segurança"
      ],
      "metadata": {
        "id": "-DcqRaoNgRTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "safety_settings = {\n",
        "    'HARASSMENT': 'BLOCK_NONE',\n",
        "    'HATE': 'BLOCK_NONE',\n",
        "    'SEXUAL': 'BLOCK_NONE',\n",
        "    'DANGEROUS': 'BLOCK_NONE',\n",
        "}"
      ],
      "metadata": {
        "id": "Jh0eqJW5fVZo"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = julIA.GenerativeModel(model_name='gemini-1.0-pro',\n",
        "                              generation_config=generation_config,\n",
        "                              safety_settings=safety_settings)"
      ],
      "metadata": {
        "id": "1Rs7DbDZkEwv"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content('Qual empresa criou a ferramenta de IA Gemini?')\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "4qyaZIEhlo1r",
        "outputId": "dd515983-4faa-41d6-fdb9-55acf59696c4"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat(history=[])"
      ],
      "metadata": {
        "id": "GH_WFg6qm3JS"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "print('Olá, meu nome é julIA, o chatbot da imersão da Alura e do Google')\n",
        "prompt = input('Em que posso ajudar hoje?\\n\\n')\n",
        "while prompt != \"fim\":\n",
        "    # Envia a mensagem do prompt para o usuário\n",
        "    response = chat.send_message(prompt)\n",
        "    print(response.text, \"\\n\")\n",
        "\n",
        "    # Loop para verificar a resposta do usuário\n",
        "    while True:\n",
        "        # Pega a entrada do usuário\n",
        "        prompt = input('Quer saber de algo mais?\\n\\n')\n",
        "\n",
        "        # Envia a resposta do chatbot para o usuário\n",
        "        response = chat.send_message(prompt)\n",
        "        print(response.text, \"\\n\")\n",
        "\n",
        "        # Verifica se o usuário deseja finalizar o chat\n",
        "        if prompt == \"fim\":\n",
        "          # Encerra o chat e exibe a mensagem de despedida\n",
        "            print(\"Obrigado por utilizar o chatbot da Imersão IA!\")\n",
        "            break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osl5_Z5aqEvT",
        "outputId": "670d5f12-5214-4107-ad09-b903bda8dfa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Olá, meu nome é julIA, o chatbot da imersão da Alura e do Google\n"
          ]
        }
      ]
    }
  ]
}